{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import northstar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning cell type by nearest neighbor in an atlas of cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assign_celltype(adata, atlas, key=\"new_celltype\", run=\"chunk\"):\n",
    "    ##Assign closest celltype from atlas\n",
    "    if run == \"chunk\":\n",
    "        new_celltype = []\n",
    "        for step in range(0, len(adata.obs_names), 1000):\n",
    "            index_chunk = adata.obs_names.tolist()[step : step + 1000]\n",
    "            chunk_data = adata[index_chunk, :]\n",
    "            model = northstar.Subsample(\n",
    "                atlas=atlas,\n",
    "                n_features_per_cell_type=100,\n",
    "                n_features_overdispersed=0,\n",
    "                features_additional=None,\n",
    "                n_pcs=50,\n",
    "                n_neighbors=0,\n",
    "                n_neighbors_external=20,\n",
    "                distance_metric=\"correlation\",\n",
    "                threshold_neighborhood=0.5,\n",
    "                clustering_metric=\"cpm\",\n",
    "                resolution_parameter=0.0001,\n",
    "                normalize_counts=True,\n",
    "                join=\"keep_first\",\n",
    "            )\n",
    "            model.fit(chunk_data)\n",
    "            cell_types_newdata = model.membership\n",
    "            new_celltype = new_celltype + [str(x) for x in cell_types_newdata]\n",
    "            del model\n",
    "        adata.obs[key] = new_celltype\n",
    "    elif run == \"all\":\n",
    "        model = northstar.Subsample(\n",
    "            atlas=atlas,\n",
    "            n_features_per_cell_type=100,\n",
    "            n_features_overdispersed=0,\n",
    "            features_additional=None,\n",
    "            n_pcs=50,\n",
    "            n_neighbors=0,\n",
    "            n_neighbors_external=20,\n",
    "            distance_metric=\"correlation\",\n",
    "            threshold_neighborhood=0.5,\n",
    "            clustering_metric=\"cpm\",\n",
    "            resolution_parameter=0.0001,\n",
    "            normalize_counts=True,\n",
    "            join=\"keep_first\",\n",
    "        )\n",
    "        model.fit(adata)\n",
    "        cell_types_newdata = model.membership\n",
    "        adata.obs[key] = [str(x) for x in cell_types_newdata]\n",
    "    else:\n",
    "        print(f'Run must equal one of [\"chunk\",\"all\"]')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary of stats of interest for every combination of obs columnd in anndata object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_dict(adata, obs_list):\n",
    "    \"\"\"Creates dictionary of all stats for every combination of metadata in obs_list\n",
    "    \n",
    "    cell type category has to be first in obs list for this to work\n",
    "    \"\"\"\n",
    "    condensed_dictionary = {}\n",
    "    num_obs = len(obs_list) + 1\n",
    "    for ind in range(0, num_obs):\n",
    "        for subset in itertools.combinations(obs_list, ind):\n",
    "            if len(subset) != 0:\n",
    "                subset = list(subset)\n",
    "                key = \"_\".join(subset)\n",
    "                if obs_list[0] not in subset: #\n",
    "                    continue\n",
    "                print(subset)\n",
    "                if len(subset) == 1:\n",
    "                    adata.obs[key] = adata.obs[subset].values\n",
    "                else:\n",
    "                    adata.obs[key] = [\"_\".join(x) for x in adata.obs[subset].values]\n",
    "                run_stats(adata, condensed_dictionary, key)\n",
    "    return condensed_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect stats for each obs column and return to dictionary\n",
    "### cell count\n",
    "### gene expresion matrix\n",
    "### proportion expressing matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_stats(adata, dct, key, mean=\"all\"):\n",
    "    \"\"\"internal function of condense_adata functions\"\"\"\n",
    "    index = sorted(adata.obs[key].unique())\n",
    "    ## counts, averages and proportions for each obs/var column in list\n",
    "    dct[key] = {}\n",
    "    obs_value_count = pd.DataFrame(adata.obs[key].value_counts()).T\n",
    "    dct[key][\"cell_count\"] = obs_value_count\n",
    "    if mean == \"all\":\n",
    "        gene_expr_mtx = pd.DataFrame(columns=adata.var_names, index=index, dtype = np.float16)\n",
    "        gene_perecent_expr_mtx = pd.DataFrame(columns=adata.var_names, index=index, dtype = np.float16)\n",
    "        for group in index:\n",
    "            group_adata = adata[adata.obs[key].isin([group]), :].copy()\n",
    "            gene_expr_mtx.loc[group] = group_adata.X.mean(0)\n",
    "            gene_perecent_expr_mtx.loc[group] = np.array(\n",
    "                np.squeeze((group_adata.X > 0).sum(axis=0)) / len(group_adata.obs_names)\n",
    "            )\n",
    "        dct[key][\"gene_expression_average\"] = gene_expr_mtx\n",
    "        dct[key][\"gene_proportion_expression\"] = gene_perecent_expr_mtx\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write condensed stats dict to .h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condense_adata_metadata(adata, obs_list, output):\n",
    "    condensed_dictionary = stats_dict(adata, obs_list)\n",
    "    hdf = pd.HDFStore(output)\n",
    "    for key in condensed_dictionary.keys():\n",
    "        for key2 in condensed_dictionary[key].keys():\n",
    "            hdf.put(f\"{key}/{key2}\", condensed_dictionary[key][key2])\n",
    "    hdf.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load datasets and do some final cleaning to align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data handling for alignment\n",
    "# ACZ datase\n",
    "acz_adata = sc.read(\n",
    "    \"./h5ads/ACZ_zanini_nornmoxia.gz.h5ad\"\n",
    ")\n",
    "sc.pp.normalize_total(acz_adata, target_sum=1e6, key_added=\"coverage\")\n",
    "acz_adata.obs[\"CellType\"] = acz_adata.obs[\"cellSubtype\"]\n",
    "acz_adata.obs[\"NumberOfCells\"] = [\n",
    "    acz_adata.obs[\"CellType\"].value_counts()[x] for x in acz_adata.obs[\"CellType\"]\n",
    "]\n",
    "acz_adata.obs[\"dataset\"] = \"ACZ\"\n",
    "acz_adata = acz_adata[acz_adata.obs[\"Treatment\"] == \"normal\", :]\n",
    "acz_adata.X = acz_adata.X.todense()\n",
    "\n",
    "# TMS datase\n",
    "tms_adata = sc.read(\n",
    "    \"./h5ads/TMS_tabula_muris_senis_facs.gz.h5ad\"\n",
    ")\n",
    "sc.pp.normalize_total(tms_adata, target_sum=1e6, key_added=\"coverage\")\n",
    "tms_adata.obs[\"dataset\"] = \"TMS\"\n",
    "\n",
    "# Hurskainen2021 datase\n",
    "hurs_adata = sc.read(\n",
    "    \"./h5ads/hurskainen2021_normoxia.gz.h5ad\"\n",
    ")\n",
    "sc.pp.normalize_total(hurs_adata, target_sum=1e6, key_added=\"coverage\")\n",
    "hurs_adata.obs[\"dataset\"] = \"Hurskainen2021\"\n",
    "hurs_adata = hurs_adata[hurs_adata.obs[\"Treatment\"] == \"Normoxia\", :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create condensed atlas and save combined h5ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to set attribute `.obs` of view, copying.\n",
      "Trying to set attribute `.obs` of view, copying.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['celltype']\n",
      "['celltype', 'dataset']\n",
      "['celltype', 'timepoint']\n",
      "['celltype', 'dataset', 'timepoint']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'DC' as categorical\n",
      "... storing 'Gender' as categorical\n",
      "... storing 'Mousename' as categorical\n",
      "... storing 'SortType' as categorical\n",
      "... storing 'Time [days]' as categorical\n",
      "... storing 'Timepoint' as categorical\n",
      "... storing 'TimepointHO' as categorical\n",
      "... storing 'Treatment' as categorical\n",
      "... storing 'Well' as categorical\n",
      "... storing 'cellRoughSubtype' as categorical\n",
      "... storing 'cellSubtype' as categorical\n",
      "... storing 'cellSubtypeOld' as categorical\n",
      "... storing 'cellType' as categorical\n",
      "... storing 'fastq' as categorical\n",
      "... storing 'CellType' as categorical\n",
      "... storing 'dataset' as categorical\n",
      "... storing 'celltype' as categorical\n",
      "... storing 'FACS.selection' as categorical\n",
      "... storing 'cell' as categorical\n",
      "... storing 'cell_ontology_class' as categorical\n",
      "... storing 'cell_ontology_id' as categorical\n",
      "... storing 'free_annotation' as categorical\n",
      "... storing 'method' as categorical\n",
      "... storing 'subtissue' as categorical\n",
      "... storing 'tissue' as categorical\n",
      "... storing 'lineage' as categorical\n",
      "... storing 'new_celltype' as categorical\n",
      "... storing 'orig.ident' as categorical\n",
      "... storing 'Barcode' as categorical\n",
      "... storing 'Phase' as categorical\n",
      "... storing 'Sample' as categorical\n",
      "... storing 'cluster_high_res' as categorical\n",
      "... storing 'timepoint' as categorical\n",
      "... storing 'celltype_dataset' as categorical\n",
      "... storing 'celltype_timepoint' as categorical\n",
      "... storing 'celltype_dataset_timepoint' as categorical\n"
     ]
    }
   ],
   "source": [
    "# create condensed atlas\n",
    "atlas = northstar.subsample_atlas(acz_adata, n_cells=50)\n",
    "obs_list = [\n",
    "    \"dataset\",\n",
    "    \"new_celltype\",\n",
    "    \"Timepoint\",\n",
    "]\n",
    "new_datasets = [tms_adata, hurs_adata]\n",
    "for adata in new_datasets:\n",
    "    assign_celltype(adata, atlas)\n",
    "    adata.obs[\"celltype\"] = adata.obs[\"new_celltype\"]\n",
    "acz_adata.obs[\"celltype\"] = acz_adata.obs[\"cellSubtype\"]\n",
    "final_adata = acz_adata.concatenate(new_datasets, join=\"outer\", fill_value=0)\n",
    "final_adata.obs[\"timepoint\"] = final_adata.obs[\"Timepoint\"]\n",
    "\n",
    "condense_adata_metadata(\n",
    "    final_adata,\n",
    "    [\"celltype\", \"dataset\", \"timepoint\"],\n",
    "    output=\"./output/condensed_lung_atlas_in_cpm.h5\",\n",
    ")\n",
    "del final_adata.var\n",
    "final_adata.write(\n",
    "    \"./output/all_lung_atlas.gz.h5ad\",\n",
    "    compression=\"gzip\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
